{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Project\n",
    "**Exploring Hacker News Posts**\n",
    "\n",
    "Hacker News is a site started by the startup incubator [Y Combinator](https://www.ycombinator.com/), where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "The data set can be found [here](https://www.kaggle.com/hacker-news/hacker-news-posts), but it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. Below are descriptions of the columns:\n",
    "\n",
    "- id: The unique identifier from Hacker News for the post\n",
    "- title: The title of the post\n",
    "- url: The URL that the posts links to, if it the post has a URL\n",
    "- num_points: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "- num_comments: The number of comments that were made on the post\n",
    "- author: The username of the person who submitted the post\n",
    "- xcreated_at: The date and time at which the post was submitted\n",
    "This project's objective is therefore to analyze the posts in the Hacker News site.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the hacker_news.csv file:\n",
    "opened_file = open('hacker_news.csv')\n",
    "from csv import reader\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "hn[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01'],\n",
       " ['10301696',\n",
       "  'Note by Note: The Making of Steinway L1037 (2007)',\n",
       "  'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',\n",
       "  '8',\n",
       "  '2',\n",
       "  'walterbell',\n",
       "  '9/30/2015 4:12']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #extracting the header\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(headers)\n",
    "hn[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having removed the headers from hn, we're ready to filter our data. Since we're only concerned with post titles beginning with Ask HN or Show HN, we'll create new lists of lists containing just the data for those titles.\n",
    "We'll use the string ,method *startswith*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of ask posts is: 1744\n",
      "The number of show posts is: 1162\n",
      "The number of other posts is: 17194\n"
     ]
    }
   ],
   "source": [
    "#create empty lists\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "#looping through each row to find number of posts in each of\n",
    "#the stated categories\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    \n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(title)\n",
    "        \n",
    "print('The number of ask posts is: ' + str(len(ask_posts)))\n",
    "print('The number of show posts is: ' + str(len(show_posts)))\n",
    "print('The number of other posts is: ' + str(len(other_posts)))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above has separated the \"ask posts\" and the \"show posts\" into two list of lists named ask_posts and show_posts.\n",
    "\n",
    "Next, we'll determine which, among the two, received more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55'], ['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43'], ['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14']]\n"
     ]
    }
   ],
   "source": [
    "print(ask_posts[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average comments on ask posts is: 14.038417431192661\n",
      "The average comments on show posts is: 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for item in ask_posts:\n",
    "    num_comments = int(item[4])\n",
    "    total_ask_comments += num_comments\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "print('The average comments on ask posts is: ' + str(avg_ask_comments))\n",
    "\n",
    "total_show_comments = 0\n",
    "for item in show_posts:\n",
    "    num_comments = int(item[4])\n",
    "    total_show_comments += num_comments\n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "print('The average comments on show posts is: ' + str(avg_show_comments)\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above, ask posts receive more comments on average.\n",
    "\n",
    "Next, we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'02': 1381, '06': 397, '20': 1722, '01': 683, '22': 479, '11': 641, '14': 1416, '13': 1253, '05': 464, '19': 1188, '08': 492, '10': 793, '18': 1439, '15': 4477, '09': 251, '07': 267, '17': 1146, '03': 421, '21': 1745, '04': 337, '00': 447, '16': 1814, '23': 543, '12': 687}\n",
      "{'02': 58, '06': 44, '20': 80, '01': 60, '22': 71, '11': 58, '14': 107, '13': 85, '05': 46, '19': 110, '08': 48, '10': 59, '18': 109, '15': 116, '09': 45, '07': 34, '17': 100, '03': 54, '21': 109, '04': 47, '00': 55, '16': 108, '23': 68, '12': 73}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "result_list = []\n",
    "for post in ask_posts:\n",
    "    date_created = post[6]\n",
    "    num_of_comments = int(post[4])\n",
    "    result_list.append([date_created, num_of_comments])\n",
    "    \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "for row in result_list:\n",
    "    created_date = row[0]\n",
    "    comment = row[1]\n",
    "    \n",
    "    parsed_date = dt.datetime.strptime(created_date, date_format)\n",
    "    hour_created = parsed_date.strftime(\"%H\")\n",
    "    \n",
    "    if hour_created not in counts_by_hour:\n",
    "        counts_by_hour[hour_created] = 1\n",
    "        comments_by_hour[hour_created] = comment\n",
    "    else:\n",
    "        counts_by_hour[hour_created] += 1\n",
    "        comments_by_hour[hour_created] += comment \n",
    "        \n",
    "print(comments_by_hour)\n",
    "print(counts_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use these two dictionaries, _counts_by_hour and comments_by_hour to calculate the average number of comments for posts created during each hour of the day.\n",
    "\n",
    "To achieve this, we need to create a list of lists containing the hours during which posts were created and the average number of comments those posts received.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of comments per ask post per hour is: [['02', 23.810344827586206], ['06', 9.022727272727273], ['20', 21.525], ['01', 11.383333333333333], ['22', 6.746478873239437], ['11', 11.051724137931034], ['14', 13.233644859813085], ['13', 14.741176470588234], ['05', 10.08695652173913], ['19', 10.8], ['08', 10.25], ['10', 13.440677966101696], ['18', 13.20183486238532], ['15', 38.5948275862069], ['09', 5.5777777777777775], ['07', 7.852941176470588], ['17', 11.46], ['03', 7.796296296296297], ['21', 16.009174311926607], ['04', 7.170212765957447], ['00', 8.127272727272727], ['16', 16.796296296296298], ['23', 7.985294117647059], ['12', 9.41095890410959]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for hour_created in comments_by_hour:\n",
    "    average = (comments_by_hour[hour_created])/ (counts_by_hour[hour_created])\n",
    "    avg_by_hour.append([hour_created, average ])\n",
    "    \n",
    "print(\"The average number of comments per ask post per hour is: \" +\n",
    "      str(avg_by_hour))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To finish, we need to sort the list of lists to identify hours with highest values, and print the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.810344827586206, '02'], [9.022727272727273, '06'], [21.525, '20'], [11.383333333333333, '01'], [6.746478873239437, '22'], [11.051724137931034, '11'], [13.233644859813085, '14'], [14.741176470588234, '13'], [10.08695652173913, '05'], [10.8, '19'], [10.25, '08'], [13.440677966101696, '10'], [13.20183486238532, '18'], [38.5948275862069, '15'], [5.5777777777777775, '09'], [7.852941176470588, '07'], [11.46, '17'], [7.796296296296297, '03'], [16.009174311926607, '21'], [7.170212765957447, '04'], [8.127272727272727, '00'], [16.796296296296298, '16'], [7.985294117647059, '23'], [9.41095890410959, '12']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for hour in avg_by_hour:\n",
    "    swap_avg_by_hour.append([hour[1], hour[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post.\n",
      "02:00: 23.81 average comments per post.\n",
      "20:00: 21.52 average comments per post.\n",
      "16:00: 16.80 average comments per post.\n",
      "21:00: 16.01 average comments per post.\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "\n",
    "for row in sorted_swap[:5]:\n",
    "    average = row[0]\n",
    "    hour = row[1]\n",
    "    \n",
    "    hour_format = \"%H\"\n",
    "    new_hour = dt.datetime.strptime(hour, hour_format)\n",
    "    hour = new_hour.strftime(\"%H:%M\")\n",
    "    \n",
    "    output = \"{a}: {b:.2f} average comments per post.\".format(a = hour, b = average)\n",
    "    print(output)   \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1500hrs(EST)** have the highest average comments per post, therefore it is advisable to create a post at this time to have a higher chance of receiving comments."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
